{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3db4fede",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5ebcea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.io.formats.style import Styler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "import optuna\n",
    "import wandb\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.callback import EarlyStopping\n",
    "import lightgbm as lgbm\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "from umap import UMAP\n",
    "\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append('..')\n",
    "from config import CFG\n",
    "from src.data_processing.fi import get_fi\n",
    "CFG = CFG()\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.set_option('display.max_columns', CFG.NCOLS)\n",
    "pd.set_option('display.max_rows', CFG.NROWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8923c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Style, Fore\n",
    "red = Style.BRIGHT + Fore.RED\n",
    "blu = Style.BRIGHT + Fore.BLUE\n",
    "mgt = Style.BRIGHT + Fore.MAGENTA\n",
    "grn = Style.BRIGHT + Fore.GREEN\n",
    "gld = Style.BRIGHT + Fore.YELLOW\n",
    "res = Style.RESET_ALL\n",
    "\n",
    "rc = {\n",
    "    \"axes.facecolor\": \"#FFFEF8\",\n",
    "    \"figure.facecolor\": \"#FFFEF8\",\n",
    "    \"axes.edgecolor\": \"#000000\",\n",
    "    \"grid.color\": \"#EBEBE7\" + \"30\",\n",
    "    \"font.family\": \"serif\",\n",
    "    \"axes.labelcolor\": \"#000000\",\n",
    "    \"xtick.color\": \"#000000\",\n",
    "    \"ytick.color\": \"#000000\",\n",
    "    \"grid.alpha\": 0.4\n",
    "}\n",
    "sns.set(rc=rc)\n",
    "palette = ['#302c36', '#037d97', '#E4591E', '#C09741',\n",
    "           '#EC5B6D', '#90A6B1', '#6ca957', '#D8E3E2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16fb2817",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "config['scaler'] = \"standard\"\n",
    "\n",
    "scaled_tr = pd.DataFrame(scaler.fit_transform(train.drop(\"Class\", axis=1)), columns=train.drop(\"Class\", axis=1).columns)\n",
    "scaled_tr[\"Class\"] = train[\"Class\"]\n",
    "\n",
    "scaled_orig = pd.DataFrame(scaler.fit_transform(orig.drop(\"Class\", axis=1)), columns=orig.drop(\"Class\", axis=1).columns)\n",
    "scaled_orig[\"Class\"] = orig[\"Class\"]\n",
    "\n",
    "scaled_tst = pd.DataFrame(scaler.transform(test), columns=test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb00316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = pd.read_csv(os.path.join(CFG.RAW_DATA, 'Pulsar.csv'))\n",
    "train = pd.read_csv(os.path.join(CFG.RAW_DATA, 'train.csv')).drop(columns='id')\n",
    "test = pd.read_csv(os.path.join(CFG.RAW_DATA, 'test.csv')).drop(columns='id')\n",
    "\n",
    "config = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0be5dc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "config['scaler'] = \"standard\"\n",
    "\n",
    "scaled_tr = pd.DataFrame(scaler.fit_transform(train.drop(\"Class\", axis=1)), columns=train.drop(\"Class\", axis=1).columns)\n",
    "scaled_tr[\"Class\"] = train[\"Class\"]\n",
    "\n",
    "scaled_orig = pd.DataFrame(scaler.fit_transform(orig.drop(\"Class\", axis=1)), columns=orig.drop(\"Class\", axis=1).columns)\n",
    "scaled_orig[\"Class\"] = orig[\"Class\"]\n",
    "\n",
    "scaled_tst = pd.DataFrame(scaler.transform(test), columns=test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d95d3288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_components(df):\n",
    "    n_components = df.shape[1]\n",
    "    pca = PCA(n_components=n_components, random_state=CFG.SEED)\n",
    "    \n",
    "    components = pca.fit_transform(df)\n",
    "    components = pd.DataFrame(components, columns=[f'PC{i}' for i in range(n_components)])\n",
    "    components['Class'] = df['Class']\n",
    "    exp_var = pca.explained_variance_ratio_\n",
    "    exp_var_cumsum = np.cumsum(exp_var)\n",
    "    return components, exp_var, exp_var_cumsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee4f7e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "components, exp_var, exp_var_cumsum = get_n_components(scaled_tr)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=list(range(len(exp_var_cumsum))),\n",
    "        y=exp_var_cumsum,\n",
    "        name='Cumulative Explained Variance',\n",
    "        line=dict(color=palette[0], width=2),\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=list(range(len(exp_var_cumsum))),\n",
    "        y=exp_var,\n",
    "        name='Explained Variance',\n",
    "        marker_color=palette[1],\n",
    "        width=0.7,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=dict(title='Principal Components', titlefont_size=20, tickfont_size=16),\n",
    "    yaxis=dict(title='Explained Variance', titlefont_size=20, tickfont_size=16),\n",
    "    height=500, width=1000, title_text='Explained Variance by Principal Components', title_x=0.5, titlefont_size=24,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77a706a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_transform(train, test, N):\n",
    "    pca = PCA(n_components=N, random_state=CFG.SEED)\n",
    "    X = pca.fit_transform(train.drop(\"Class\", axis=1))\n",
    "    X = pd.DataFrame(X, columns=[f'PC{i}' for i in range(N)])\n",
    "    y = train['Class']\n",
    "    return pca.transform(test), X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ee1fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "config['n_components'] = N\n",
    "\n",
    "X_test, X, y = pca_transform(scaled_tr, scaled_tst, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4d2ab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = RepeatedStratifiedKFold(n_splits=CFG.NFOLDS, n_repeats=CFG.REPEATS, random_state=CFG.SEED)\n",
    "\n",
    "modelsXB = []\n",
    "predsXB = []\n",
    "\n",
    "# gpu_params = {'tree_method' : \"gpu_hist\", 'gpu_id' : 0}\n",
    "xgbr_params = {\n",
    "            'n_estimators':9999,\n",
    "            'max_depth': 4,\n",
    "            'learning_rate': 0.05333221939055333,\n",
    "            'min_child_weight': 4,\n",
    "            'gamma': 5.301218558776368e-08,\n",
    "            'subsample': 0.41010429946197946,\n",
    "            'colsample_bytree': 0.8298539920447499,\n",
    "            'reg_alpha': 0.000517878113716743,\n",
    "            'reg_lambda': 0.00030121415155097723,\n",
    "            'n_jobs': -1,\n",
    "            'objective': 'binary:logistic',\n",
    "            'verbosity': 0,\n",
    "            'eval_metric': 'logloss',\n",
    "            'random_state': CFG.SEED}\n",
    "\n",
    "config.update({key:val for key, val in xgbr_params.items() if key not in ['random_state', 'eval_metric', 'verbosity', 'objective', 'n_jobs']})\n",
    "wandb.init(project='S3E10', name='XGBoost', group='XGBoost', config=config)\n",
    "\n",
    "for train_index, test_index in k_fold.split(X, y):\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model = xgb.XGBClassifier(**xgbr_params)\n",
    "    \n",
    "    model.fit(X=X_train, y=y_train,\n",
    "          eval_set=[(X_valid, y_valid)],\n",
    "          early_stopping_rounds = CFG.XG_PATIENCE,\n",
    "          verbose = 100, callbacks=[wandb.xgboost.WandbCallback(log_model=False)]\n",
    "         )\n",
    "    modelsXB.append(model)\n",
    "    predsXB.append(model.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a03c75b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2aa84da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.io.formats.style import Styler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "import optuna\n",
    "import wandb\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.callback import EarlyStopping\n",
    "import lightgbm as lgbm\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "from umap import UMAP\n",
    "\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append('..')\n",
    "from config import CFG\n",
    "from src.data_processing.fi import get_fi\n",
    "CFG = CFG()\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.set_option('display.max_columns', CFG.NCOLS)\n",
    "pd.set_option('display.max_rows', CFG.NROWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29642650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Style, Fore\n",
    "red = Style.BRIGHT + Fore.RED\n",
    "blu = Style.BRIGHT + Fore.BLUE\n",
    "mgt = Style.BRIGHT + Fore.MAGENTA\n",
    "grn = Style.BRIGHT + Fore.GREEN\n",
    "gld = Style.BRIGHT + Fore.YELLOW\n",
    "res = Style.RESET_ALL\n",
    "\n",
    "rc = {\n",
    "    \"axes.facecolor\": \"#FFFEF8\",\n",
    "    \"figure.facecolor\": \"#FFFEF8\",\n",
    "    \"axes.edgecolor\": \"#000000\",\n",
    "    \"grid.color\": \"#EBEBE7\" + \"30\",\n",
    "    \"font.family\": \"serif\",\n",
    "    \"axes.labelcolor\": \"#000000\",\n",
    "    \"xtick.color\": \"#000000\",\n",
    "    \"ytick.color\": \"#000000\",\n",
    "    \"grid.alpha\": 0.4\n",
    "}\n",
    "sns.set(rc=rc)\n",
    "palette = ['#302c36', '#037d97', '#E4591E', '#C09741',\n",
    "           '#EC5B6D', '#90A6B1', '#6ca957', '#D8E3E2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e500176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = pd.read_csv(os.path.join(CFG.RAW_DATA, 'Pulsar.csv'))\n",
    "train = pd.read_csv(os.path.join(CFG.RAW_DATA, 'train.csv')).drop(columns='id')\n",
    "test = pd.read_csv(os.path.join(CFG.RAW_DATA, 'test.csv')).drop(columns='id')\n",
    "\n",
    "config = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "642d8504",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "config['scaler'] = \"standard\"\n",
    "\n",
    "scaled_tr = pd.DataFrame(scaler.fit_transform(train.drop(\"Class\", axis=1)), columns=train.drop(\"Class\", axis=1).columns)\n",
    "scaled_tr[\"Class\"] = train[\"Class\"]\n",
    "\n",
    "scaled_orig = pd.DataFrame(scaler.fit_transform(orig.drop(\"Class\", axis=1)), columns=orig.drop(\"Class\", axis=1).columns)\n",
    "scaled_orig[\"Class\"] = orig[\"Class\"]\n",
    "\n",
    "scaled_tst = pd.DataFrame(scaler.transform(test), columns=test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0315e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_components(df):\n",
    "    n_components = df.shape[1]\n",
    "    pca = PCA(n_components=n_components, random_state=CFG.SEED)\n",
    "    \n",
    "    components = pca.fit_transform(df)\n",
    "    components = pd.DataFrame(components, columns=[f'PC{i}' for i in range(n_components)])\n",
    "    components['Class'] = df['Class']\n",
    "    exp_var = pca.explained_variance_ratio_\n",
    "    exp_var_cumsum = np.cumsum(exp_var)\n",
    "    return components, exp_var, exp_var_cumsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d95bee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "components, exp_var, exp_var_cumsum = get_n_components(scaled_tr)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=list(range(len(exp_var_cumsum))),\n",
    "        y=exp_var_cumsum,\n",
    "        name='Cumulative Explained Variance',\n",
    "        line=dict(color=palette[0], width=2),\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=list(range(len(exp_var_cumsum))),\n",
    "        y=exp_var,\n",
    "        name='Explained Variance',\n",
    "        marker_color=palette[1],\n",
    "        width=0.7,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=dict(title='Principal Components', titlefont_size=20, tickfont_size=16),\n",
    "    yaxis=dict(title='Explained Variance', titlefont_size=20, tickfont_size=16),\n",
    "    height=500, width=1000, title_text='Explained Variance by Principal Components', title_x=0.5, titlefont_size=24,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d2864d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_transform(train, test, N):\n",
    "    pca = PCA(n_components=N, random_state=CFG.SEED)\n",
    "    X = pca.fit_transform(train.drop(\"Class\", axis=1))\n",
    "    X = pd.DataFrame(X, columns=[f'PC{i}' for i in range(N)])\n",
    "    y = train['Class']\n",
    "    return pca.transform(test), X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef92d5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "config['n_components'] = N\n",
    "\n",
    "X_test, X, y = pca_transform(scaled_tr, scaled_tst, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53bd01a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = RepeatedStratifiedKFold(n_splits=CFG.NFOLDS, n_repeats=CFG.REPEATS, random_state=CFG.SEED)\n",
    "\n",
    "modelsXB = []\n",
    "predsXB = []\n",
    "\n",
    "# gpu_params = {'tree_method' : \"gpu_hist\", 'gpu_id' : 0}\n",
    "xgbr_params = {\n",
    "            'n_estimators':9999,\n",
    "            'max_depth': 4,\n",
    "            'learning_rate': 0.05333221939055333,\n",
    "            'min_child_weight': 4,\n",
    "            'gamma': 5.301218558776368e-08,\n",
    "            'subsample': 0.41010429946197946,\n",
    "            'colsample_bytree': 0.8298539920447499,\n",
    "            'reg_alpha': 0.000517878113716743,\n",
    "            'reg_lambda': 0.00030121415155097723,\n",
    "            'n_jobs': -1,\n",
    "            'objective': 'binary:logistic',\n",
    "            'verbosity': 0,\n",
    "            'eval_metric': 'logloss',\n",
    "            'random_state': CFG.SEED}\n",
    "\n",
    "config.update({key:val for key, val in xgbr_params.items() if key not in ['random_state', 'eval_metric', 'verbosity', 'objective', 'n_jobs']})\n",
    "wandb.init(project='S3E10', name='XGBoost', group='XGBoost', config=config)\n",
    "\n",
    "for train_index, test_index in k_fold.split(X, y):\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model = xgb.XGBClassifier(**xgbr_params)\n",
    "    \n",
    "    model.fit(X=X_train, y=y_train,\n",
    "          eval_set=[(X_valid, y_valid)],\n",
    "          early_stopping_rounds = CFG.XG_PATIENCE,\n",
    "          verbose = 100, callbacks=[wandb.xgboost.WandbCallback(log_model=False)]\n",
    "         )\n",
    "    modelsXB.append(model)\n",
    "    predsXB.append(model.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d87a6681",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance =  [model[x].feature_importances_ for x in range(CFG.NFOLDS*CFG.REPEATS)]\n",
    "feature_importance = np.average(feature_importance,axis=0)\n",
    "data = [[label, value] for (label, value) in zip(X.columns, feature_importance)]\n",
    "\n",
    "table = wandb.Table(data=data, columns=['label', 'value'])\n",
    "wandb.log({'XGBoost_Feature_Importance': wandb.plot_bar(table, 'label', 'value', title=\"Feature Importance\")})\n",
    "# feature_df = pd.DataFrame(feature_importance, index=X.columns)\n",
    "# feature_df\n",
    "# wandb.Table\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(12, 4))\n",
    "# sns.barplot(x=feature_df.values.squeeze(), y=feature_df.index,\n",
    "#             color=palette[-3], linestyle=\"-\", width=0.5, errorbar='sd',\n",
    "#             linewidth=0.5, edgecolor=\"black\", ax=ax)\n",
    "# ax.set_title('Feature Importance', fontdict={'fontweight': 'bold'})\n",
    "# ax.set(xlabel=None)\n",
    "\n",
    "# for s in ['right', 'top']:\n",
    "#     ax.spines[s].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28be7b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "[model[x].feature_importances_ for x in range(CFG.NFOLDS*CFG.REPEATS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9467143f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.7111551 , 0.16333364, 0.12551117], dtype=float32),\n",
      " array([0.71454674, 0.16249926, 0.12295397], dtype=float32),\n",
      " array([0.70543176, 0.17237453, 0.12219369], dtype=float32),\n",
      " array([0.72080547, 0.16008782, 0.11910668], dtype=float32),\n",
      " array([0.6976138 , 0.17023507, 0.13215113], dtype=float32),\n",
      " array([0.718605  , 0.16489132, 0.11650369], dtype=float32),\n",
      " array([0.71374947, 0.16561152, 0.12063902], dtype=float32),\n",
      " array([0.7162871 , 0.1660631 , 0.11764979], dtype=float32),\n",
      " array([0.69904864, 0.17194287, 0.12900849], dtype=float32)]"
     ]
    }
   ],
   "source": [
    "[modelsXB[x].feature_importances_ for x in range(CFG.NFOLDS*CFG.REPEATS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f0a8d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance =  [modelsXB[x].feature_importances_ for x in range(CFG.NFOLDS*CFG.REPEATS)]\n",
    "feature_importance = np.average(feature_importance,axis=0)\n",
    "data = [[label, value] for (label, value) in zip(X.columns, feature_importance)]\n",
    "\n",
    "table = wandb.Table(data=data, columns=['label', 'value'])\n",
    "wandb.log({'XGBoost_Feature_Importance': wandb.plot_bar(table, 'label', 'value', title=\"Feature Importance\")})\n",
    "# feature_df = pd.DataFrame(feature_importance, index=X.columns)\n",
    "# feature_df\n",
    "# wandb.Table\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(12, 4))\n",
    "# sns.barplot(x=feature_df.values.squeeze(), y=feature_df.index,\n",
    "#             color=palette[-3], linestyle=\"-\", width=0.5, errorbar='sd',\n",
    "#             linewidth=0.5, edgecolor=\"black\", ax=ax)\n",
    "# ax.set_title('Feature Importance', fontdict={'fontweight': 'bold'})\n",
    "# ax.set(xlabel=None)\n",
    "\n",
    "# for s in ['right', 'top']:\n",
    "#     ax.spines[s].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9884f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance =  [modelsXB[x].feature_importances_ for x in range(CFG.NFOLDS*CFG.REPEATS)]\n",
    "feature_importance = np.average(feature_importance,axis=0)\n",
    "data = [[label, value] for (label, value) in zip(X.columns, feature_importance)]\n",
    "\n",
    "table = wandb.Table(data=data, columns=['label', 'value'])\n",
    "wandb.log({'XGBoost_Feature_Importance': wandb.plot.bar(table, 'label', 'value', title=\"Feature Importance\")})\n",
    "# feature_df = pd.DataFrame(feature_importance, index=X.columns)\n",
    "# feature_df\n",
    "# wandb.Table\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(12, 4))\n",
    "# sns.barplot(x=feature_df.values.squeeze(), y=feature_df.index,\n",
    "#             color=palette[-3], linestyle=\"-\", width=0.5, errorbar='sd',\n",
    "#             linewidth=0.5, edgecolor=\"black\", ax=ax)\n",
    "# ax.set_title('Feature Importance', fontdict={'fontweight': 'bold'})\n",
    "# ax.set(xlabel=None)\n",
    "\n",
    "# for s in ['right', 'top']:\n",
    "#     ax.spines[s].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7bbe77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7486279",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance =  [modelsLB[x].feature_importances_ for x in range(CFG.NFOLDS*CFG.REPEATS)]\n",
    "feature_importance = np.average(feature_importance,axis=0)\n",
    "data = [[label, value] for (label, value) in zip(X.columns, feature_importance)]\n",
    "\n",
    "table = wandb.Table(data=data, columns=['label', 'value'])\n",
    "wandb.log({'LGBM_Feature_Importance': wandb.plot.bar(table, 'label', 'value', title=\"Feature Importance\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a16038f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/broug/Desktop/S3E10/notebooks/wandb/run-20230318_230527-zkhyfrth</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g-broughton/S3E10/runs/zkhyfrth' target=\"_blank\">LightGBM</a></strong> to <a href='https://wandb.ai/g-broughton/S3E10' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g-broughton/S3E10' target=\"_blank\">https://wandb.ai/g-broughton/S3E10</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g-broughton/S3E10/runs/zkhyfrth' target=\"_blank\">https://wandb.ai/g-broughton/S3E10/runs/zkhyfrth</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelsLB = []\n",
    "predsLB = []\n",
    "\n",
    "lgbr_params = {\n",
    "            'n_estimators': 9999,\n",
    "            'max_depth': 5,\n",
    "            'learning_rate': 0.00693702575527996,\n",
    "            'subsample': 0.20851841295589477,\n",
    "            'colsample_bytree': 0.5784778854092203, \n",
    "            'reg_alpha': 0.2622912287429849,\n",
    "            'reg_lambda': 2.8702494234117617e-08,\n",
    "            'objective': 'binary',\n",
    "            'metric': 'logloss',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'random_state': CFG.SEED\n",
    "        }\n",
    "config = {} | {\n",
    "    key: value for key, value in lgbr_params.items() if key not in ['']\n",
    "}\n",
    "wandb.init(project='S3E10', name='LightGBM', group='LightGBM', config=config, reinit=True)\n",
    "\n",
    "for train_index, test_index in k_fold.split(X, y):\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model = lgbm.LGBMClassifier(**lgbr_params)\n",
    "\n",
    "    model.fit(X=X_train, y=y_train,\n",
    "          eval_set=[(X_valid, y_valid)],\n",
    "          eval_metric = 'logloss',\n",
    "          early_stopping_rounds = CFG.XG_PATIENCE,\n",
    "          verbose = 150,\n",
    "          callbacks=[wandb.wandb_callback()]\n",
    "         )\n",
    "    modelsLB.append(model)\n",
    "    predsLB.append(model.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90b6c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsLB = []\n",
    "predsLB = []\n",
    "\n",
    "lgbr_params = {\n",
    "            'n_estimators': 9999,\n",
    "            'max_depth': 5,\n",
    "            'learning_rate': 0.00693702575527996,\n",
    "            'subsample': 0.20851841295589477,\n",
    "            'colsample_bytree': 0.5784778854092203, \n",
    "            'reg_alpha': 0.2622912287429849,\n",
    "            'reg_lambda': 2.8702494234117617e-08,\n",
    "            'objective': 'binary',\n",
    "            'metric': 'logloss',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'random_state': CFG.SEED\n",
    "        }\n",
    "config = {} | {\n",
    "    key: value for key, value in lgbr_params.items() if key not in ['']\n",
    "}\n",
    "wandb.init(project='S3E10', name='LightGBM', group='LightGBM', config=config, reinit=True)\n",
    "\n",
    "for train_index, test_index in k_fold.split(X, y):\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model = lgbm.LGBMClassifier(**lgbr_params)\n",
    "\n",
    "    model.fit(X=X_train, y=y_train,\n",
    "          eval_set=[(X_valid, y_valid)],\n",
    "          eval_metric = 'logloss',\n",
    "          early_stopping_rounds = CFG.XG_PATIENCE,\n",
    "          verbose = 150,\n",
    "          callbacks=[wandb.wandb_callback()]\n",
    "         )\n",
    "    modelsLB.append(model)\n",
    "    predsLB.append(model.predict_proba(X_test)[:, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
